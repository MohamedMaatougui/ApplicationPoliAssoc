{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJXpuAPWiJi3"
      },
      "source": [
        "# Linear and Polynomial Regression for Cluster Prediction\n",
        "\n",
        "This notebook uses linear regression and polynomial regression to predict cluster associations from the dataset, after removing foreign key columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZONE9-NiJi5"
      },
      "outputs": [],
      "source": [
        "# Importations de base\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# Réglages d'affichage\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mT1pK7diJi7"
      },
      "outputs": [],
      "source": [
        "# Chemin vers les données (ajustez si nécessaire)\n",
        "\n",
        "data_path = os.path.join('Projet', 'clustered_data.csv')\n",
        "\n",
        "print('Chargement :', data_path)\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "\n",
        "# Aperçu rapide\n",
        "\n",
        "print('Taille :', df.shape)\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "display(df.dtypes)\n",
        "\n",
        "display(df.describe(include='all').T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW0EWj2YiJi7"
      },
      "outputs": [],
      "source": [
        "# Préparation des données : suppression des colonnes FK et encodage de la cible\n",
        "\n",
        "# Détection automatique des colonnes FK (heuristique sur les noms)\n",
        "\n",
        "fk_pattern = re.compile(r'(^id$|_id$|^id_|\bfk\b|_fk$|^fk_)', re.I)\n",
        "\n",
        "fk_cols = [c for c in df.columns if fk_pattern.search(c)]\n",
        "\n",
        "print('Colonnes FK détectées et exclues :', fk_cols)\n",
        "\n",
        "\n",
        "\n",
        "# Encodage de la colonne cluster (cible) en numérique pour la régression\n",
        "\n",
        "cluster_mapping = {cluster: idx for idx, cluster in enumerate(df['cluster'].unique())}\n",
        "\n",
        "df['cluster_encoded'] = df['cluster'].map(cluster_mapping)\n",
        "\n",
        "print('Mapping des clusters :', cluster_mapping)\n",
        "\n",
        "\n",
        "\n",
        "# Colonnes à retirer des features : target + FK détectées\n",
        "\n",
        "to_drop = ['cluster'] + fk_cols\n",
        "\n",
        "X = df.drop(columns=to_drop)\n",
        "\n",
        "y = df['cluster_encoded'].copy()\n",
        "\n",
        "\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "\n",
        "\n",
        "# Préprocesseur : standardisation des numériques, one-hot pour catégorielles\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "    ],\n",
        "    remainder='drop',\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Split des données\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "print('Formes après split :')\n",
        "print('X_train:', X_train.shape, 'y_train:', y_train.shape)\n",
        "print('X_test:', X_test.shape, 'y_test:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa3uJW5fiJi8"
      },
      "outputs": [],
      "source": [
        "# Régression linéaire\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "\n",
        "linear_pipeline = Pipeline(steps=[('preproc', preprocessor), ('reg', LinearRegression())])\n",
        "\n",
        "\n",
        "\n",
        "linear_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Prédictions\n",
        "\n",
        "y_train_pred_linear = linear_pipeline.predict(X_train)\n",
        "\n",
        "y_test_pred_linear = linear_pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Évaluation\n",
        "\n",
        "train_mse_linear = mean_squared_error(y_train, y_train_pred_linear)\n",
        "\n",
        "test_mse_linear = mean_squared_error(y_test, y_test_pred_linear)\n",
        "\n",
        "train_r2_linear = r2_score(y_train, y_train_pred_linear)\n",
        "\n",
        "test_r2_linear = r2_score(y_test, y_test_pred_linear)\n",
        "\n",
        "\n",
        "\n",
        "print('=== RÉGRESSION LINÉAIRE ===')\n",
        "print(f'MSE TRAIN: {train_mse_linear:.4f} | TEST: {test_mse_linear:.4f}')\n",
        "print(f'R2  TRAIN: {train_r2_linear:.4f} | TEST: {test_r2_linear:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "\n",
        "joblib.dump(linear_pipeline, 'linear_regression_cluster.joblib')\n",
        "\n",
        "print('Modèle linéaire sauvegardé : linear_regression_cluster.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmqRWuXuiJi8"
      },
      "outputs": [],
      "source": [
        "# Régression polynomiale (degré 2)\n",
        "\n",
        "poly_pipeline = Pipeline(steps=[\n",
        "    ('preproc', preprocessor),\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('reg', LinearRegression())\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "poly_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Prédictions\n",
        "\n",
        "y_train_pred_poly = poly_pipeline.predict(X_train)\n",
        "\n",
        "y_test_pred_poly = poly_pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Évaluation\n",
        "\n",
        "train_mse_poly = mean_squared_error(y_train, y_train_pred_poly)\n",
        "\n",
        "test_mse_poly = mean_squared_error(y_test, y_test_pred_poly)\n",
        "\n",
        "train_r2_poly = r2_score(y_train, y_train_pred_poly)\n",
        "\n",
        "test_r2_poly = r2_score(y_test, y_test_pred_poly)\n",
        "\n",
        "\n",
        "\n",
        "print('=== RÉGRESSION POLYNOMIALE (degré 2) ===')\n",
        "print(f'MSE TRAIN: {train_mse_poly:.4f} | TEST: {test_mse_poly:.4f}')\n",
        "print(f'R2  TRAIN: {train_r2_poly:.4f} | TEST: {test_r2_poly:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "\n",
        "joblib.dump(poly_pipeline, 'polynomial_regression_cluster.joblib')\n",
        "\n",
        "print('Modèle polynomial sauvegardé : polynomial_regression_cluster.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0TJw5tTiJi9"
      },
      "outputs": [],
      "source": [
        "# Visualisations : réel vs prédit pour les deux modèles\n",
        "\n",
        "# Linéaire\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, y_test_pred_linear, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Réel (cluster encodé)')\n",
        "plt.ylabel('Prédit (linéaire)')\n",
        "plt.title('Réel vs Prédit - Régression Linéaire')\n",
        "\n",
        "# Polynomial\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred_poly, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Réel (cluster encodé)')\n",
        "plt.ylabel('Prédit (polynomial)')\n",
        "plt.title('Réel vs Prédit - Régression Polynomiale')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJTbI0jqiJi9"
      },
      "source": [
        "## Remarques\n",
        "\n",
        "- Les clusters ont été encodés numériquement pour permettre la régression.\n",
        "- Les colonnes FK ont été automatiquement supprimées.\n",
        "- Pour améliorer les performances, vous pouvez ajuster le degré polynomial ou ajouter de la régularisation.\n",
        "- Les modèles sont sauvegardés pour une utilisation future."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du DataFrame de Sortie avec les prédictions et les clés de dimensions\n",
        "import pandas as pd\n",
        "\n",
        "# S'assurer que les indices correspondent bien pour une fusion correcte\n",
        "X_test_reset = X_test.reset_index(drop=True)\n",
        "y_test_reset = y_test.reset_index(drop=True)\n",
        "\n",
        "# Création du DataFrame de prédictions\n",
        "# On copie X_test pour conserver les colonnes de dimensions (features)\n",
        "predictions_df = X_test_reset.copy()\n",
        "\n",
        "# Ajout de la colonne avec les vraies valeurs encodées des clusters\n",
        "predictions_df['cluster_encoded_actual'] = y_test_reset\n",
        "\n",
        "# Ajout de la colonne avec les prédictions du modèle polynomial\n",
        "predictions_df['cluster_encoded_predicted_poly'] = y_test_pred_poly\n",
        "\n",
        "# --- Optionnel : Inverser l'encodage pour avoir les noms de cluster si le mapping est disponible ---\n",
        "# Pour afficher les noms de cluster réels (si le mapping est nécessaire et disponible globalement)\n",
        "# if 'cluster_mapping' in locals():\n",
        "#     reverse_cluster_mapping = {v: k for k, v in cluster_mapping.items()}\n",
        "#     predictions_df['cluster_actual'] = predictions_df['cluster_encoded_actual'].map(reverse_cluster_mapping)\n",
        "#     # Pour les prédictions, les valeurs sont des flottants, donc les mapper directement pourrait être trompeur.\n",
        "#     # On pourrait envisager d'arrondir ou d'utiliser une logique de classification pour les attribuer à un cluster 'nommé'.\n",
        "\n",
        "\n",
        "# Affichage des premières lignes du DataFrame de prédictions\n",
        "print(\"Aperçu du DataFrame de prédictions (premières 5 lignes) :\")\n",
        "display(predictions_df.head())\n",
        "\n",
        "# Exportation du DataFrame de prédictions vers un fichier CSV\n",
        "output_filename = 'cluster_predictions_polynomial_regression.csv'\n",
        "predictions_df.to_csv(output_filename, index=False)\n",
        "print(f\"\\nDataFrame de prédictions exporté avec succès sous : {output_filename}\")\n",
        "\n",
        "# Pour une visualisation complète (peut être lourd si beaucoup de données)\n",
        "# print(\"\\nInformations sur le DataFrame de prédictions :\")\n",
        "# predictions_df.info()\n"
      ],
      "metadata": {
        "id": "56pQQqCPjhKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}